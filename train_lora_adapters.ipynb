{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train LoRA Adapters for Ablation Studies\n\nThis notebook trains real LoRA adapters by fine-tuning Qwen2.5-0.5B on various tasks.\nRun this on Colab with GPU, then use the adapters in phase 4.5 ablations.\n\n**Tasks:**\n- ARC-e (science reasoning)\n- BoolQ (boolean QA)\n- GSM8K (math)\n\n**Key improvements:**\n- Uses **task-specific prompts** for delta computation (not generic probes)\n- Creates **held-out eval splits** for performance evaluation\n- Saves all necessary metadata for ablation studies\n\n**Output:** ~9 LoRA adapters + task-specific deltas + eval splits"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sorryhyun/llgbm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     !pip install -q transformers peft accelerate safetensors bitsandbytes\n",
    "    \n",
    "#     # Use Drive paths\n",
    "#     DRIVE_ROOT = '/content/drive/MyDrive/llgbm'\n",
    "#     DATA_DIR = f'{DRIVE_ROOT}/data'\n",
    "#     OUTPUT_DIR = f'{DRIVE_ROOT}/checkpoints'\n",
    "# else:\n",
    "DATA_DIR = 'data'\n",
    "OUTPUT_DIR = 'checkpoints'\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Data dir: {DATA_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: data\n",
      "Output dir: checkpoints\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "OUTPUT_DIR = 'checkpoints'\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Data dir: {DATA_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Qwen/Qwen2.5-0.5B\n",
      "LoRA: rank=8, alpha=16\n",
      "Training: 2 epochs, batch_size=4\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Model\n",
    "    model_name: str = \"Qwen/Qwen2.5-0.5B\"\n",
    "    \n",
    "    # LoRA\n",
    "    lora_rank: int = 8\n",
    "    lora_alpha: int = 16\n",
    "    lora_dropout: float = 0.05\n",
    "    target_modules: tuple = (\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\")\n",
    "    \n",
    "    # Training\n",
    "    num_epochs: int = 2\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 2e-4\n",
    "    max_length: int = 384\n",
    "    warmup_ratio: float = 0.1\n",
    "    \n",
    "    # Data\n",
    "    samples_per_adapter: int = 400\n",
    "    adapters_per_task: int = 3\n",
    "\n",
    "config = Config()\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"LoRA: rank={config.lora_rank}, alpha={config.lora_alpha}\")\n",
    "print(f\"Training: {config.num_epochs} epochs, batch_size={config.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Task definitions with eval split\nTASKS = {\n    \"arc_e\": {\n        \"file\": \"ARC-e_train.json\",\n        \"samples\": 400,\n        \"adapters\": 3,\n        \"eval_samples\": 200,  # Hold out for evaluation\n        \"delta_probes\": 16,   # Task-specific probes for delta computation\n    },\n    \"boolq\": {\n        \"file\": \"BoolQ_train.json\",\n        \"samples\": 400,\n        \"adapters\": 3,\n        \"eval_samples\": 200,\n        \"delta_probes\": 16,\n    },\n    \"gsm8k\": {\n        \"file\": \"GSM8K_train.json\",\n        \"samples\": 300,\n        \"adapters\": 3,\n        \"eval_samples\": 200,\n        \"delta_probes\": 16,\n    },\n}\n\n# Check data files exist\nfor task, info in TASKS.items():\n    path = Path(DATA_DIR) / info[\"file\"]\n    exists = path.exists()\n    print(f\"{task}: {path.name} {'[OK]' if exists else '[MISSING]'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFTDataset(Dataset):\n",
    "    \"\"\"Simple SFT dataset for instruction tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data: List[Dict], tokenizer, max_length: int = 512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        # Build chat format\n",
    "        system = item.get(\"system\", \"You are a helpful assistant.\")\n",
    "        prompt = item[\"prompt\"]\n",
    "        response = item[\"response\"]\n",
    "\n",
    "        # Qwen chat format\n",
    "        text = f\"<|im_start|>system\\n{system}<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n{response}<|im_end|>\"\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # Labels: same as input_ids, with padding tokens set to -100\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adapter(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    train_data: List[Dict],\n",
    "    output_dir: Path,\n",
    "    adapter_name: str,\n",
    "    config: Config,\n",
    "):\n",
    "    \"\"\"Train a single LoRA adapter and save it.\"\"\"\n",
    "\n",
    "    print(f\"\\n  Training: {adapter_name} ({len(train_data)} samples)\")\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = SFTDataset(train_data, tokenizer, max_length=config.max_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)\n",
    "    num_training_steps = len(dataloader) * config.num_epochs\n",
    "    num_warmup_steps = int(num_training_steps * config.warmup_ratio)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    global_step = 0\n",
    "\n",
    "    progress = tqdm(total=num_training_steps, desc=f\"  {adapter_name}\", leave=False)\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                progress.set_postfix(loss=f\"{total_loss / global_step:.4f}\")\n",
    "            progress.update(1)\n",
    "\n",
    "    progress.close()\n",
    "\n",
    "    # Save adapter\n",
    "    adapter_dir = output_dir / adapter_name\n",
    "    adapter_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(adapter_dir)\n",
    "\n",
    "    # Save training prompts (for conditioning)\n",
    "    prompts = [item[\"prompt\"] for item in train_data[:128]]\n",
    "    with open(adapter_dir / \"prompts.json\", \"w\") as f:\n",
    "        json.dump({\"prompts\": prompts, \"task\": adapter_name}, f, indent=2)\n",
    "\n",
    "    avg_loss = total_loss / global_step\n",
    "    print(f\"  Saved: {adapter_dir} (loss={avg_loss:.4f})\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lora_model(config: Config):\n",
    "    \"\"\"Load base model and apply LoRA.\"\"\"\n",
    "    \n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=device,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        r=config.lora_rank,\n",
    "        lora_alpha=config.lora_alpha,\n",
    "        lora_dropout=config.lora_dropout,\n",
    "        target_modules=list(config.target_modules),\n",
    "        bias=\"none\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Vocab size: 151665\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"Vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Task: arc_e\n",
      "============================================================\n",
      "Loaded 2251 samples\n",
      "\n",
      "Adapter 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: arc_e_000 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/arc_e/arc_e_000 (loss=1.2588)\n",
      "\n",
      "Adapter 2/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: arc_e_001 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/arc_e/arc_e_001 (loss=1.2577)\n",
      "\n",
      "Adapter 3/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: arc_e_002 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/arc_e/arc_e_002 (loss=1.2395)\n",
      "\n",
      "============================================================\n",
      "Task: boolq\n",
      "============================================================\n",
      "Loaded 9427 samples\n",
      "\n",
      "Adapter 1/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: boolq_000 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/boolq/boolq_000 (loss=1.1323)\n",
      "\n",
      "Adapter 2/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: boolq_001 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/boolq/boolq_001 (loss=1.1472)\n",
      "\n",
      "Adapter 3/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: boolq_002 (400 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/boolq/boolq_002 (loss=1.1444)\n",
      "\n",
      "============================================================\n",
      "Task: gsm8k\n",
      "============================================================\n",
      "Loaded 7473 samples\n",
      "\n",
      "Adapter 1/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: gsm8k_000 (300 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/gsm8k/gsm8k_000 (loss=0.6189)\n",
      "\n",
      "Adapter 2/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: gsm8k_001 (300 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/gsm8k/gsm8k_001 (loss=0.6613)\n",
      "\n",
      "Adapter 3/3\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
      "\n",
      "  Training: gsm8k_002 (300 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: checkpoints/gsm8k/gsm8k_002 (loss=0.6480)\n",
      "\n",
      "\n",
      "Trained 9 adapters!\n"
     ]
    }
   ],
   "source": [
    "all_adapters = []\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "\n",
    "for task_name, task_info in TASKS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Task: {task_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Load data\n",
    "    data_file = Path(DATA_DIR) / task_info[\"file\"]\n",
    "    with open(data_file) as f:\n",
    "        task_data = json.load(f)\n",
    "    print(f\"Loaded {len(task_data)} samples\")\n",
    "\n",
    "    # Train multiple adapters\n",
    "    for adapter_idx in range(task_info[\"adapters\"]):\n",
    "        # Fresh model for each adapter\n",
    "        print(f\"\\nAdapter {adapter_idx + 1}/{task_info['adapters']}\")\n",
    "        model = create_lora_model(config)\n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "        # Select data subset\n",
    "        samples = task_info[\"samples\"]\n",
    "        start_idx = adapter_idx * samples\n",
    "        end_idx = start_idx + samples\n",
    "        \n",
    "        if end_idx > len(task_data):\n",
    "            subset = task_data[start_idx:] + task_data[:end_idx - len(task_data)]\n",
    "        else:\n",
    "            subset = task_data[start_idx:end_idx]\n",
    "\n",
    "        adapter_name = f\"{task_name}_{adapter_idx:03d}\"\n",
    "\n",
    "        # Train\n",
    "        loss = train_adapter(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            train_data=subset,\n",
    "            output_dir=output_path / task_name,\n",
    "            adapter_name=adapter_name,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        all_adapters.append({\n",
    "            \"name\": adapter_name,\n",
    "            \"task\": task_name,\n",
    "            \"path\": str(output_path / task_name / adapter_name),\n",
    "            \"loss\": loss,\n",
    "            \"samples\": len(subset),\n",
    "        })\n",
    "\n",
    "        # Cleanup\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n\\nTrained {len(all_adapters)} adapters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest saved to: checkpoints/manifest.json\n"
     ]
    }
   ],
   "source": [
    "manifest = {\n",
    "    \"model_name\": config.model_name,\n",
    "    \"lora_config\": {\n",
    "        \"rank\": config.lora_rank,\n",
    "        \"alpha\": config.lora_alpha,\n",
    "        \"target_modules\": list(config.target_modules),\n",
    "    },\n",
    "    \"adapters\": all_adapters,\n",
    "}\n",
    "\n",
    "with open(output_path / \"manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(f\"Manifest saved to: {output_path / 'manifest.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Create eval splits for each task\neval_dir = output_path / \"eval_splits\"\neval_dir.mkdir(exist_ok=True)\n\nimport random\nrandom.seed(42)\n\neval_data = {}\nfor task_name, task_info in TASKS.items():\n    data_file = Path(DATA_DIR) / task_info[\"file\"]\n    with open(data_file) as f:\n        task_data = json.load(f)\n    \n    # Compute indices used for training\n    train_end = task_info[\"adapters\"] * task_info[\"samples\"]\n    \n    # Use samples after training data as eval\n    eval_samples = task_info[\"eval_samples\"]\n    eval_start = train_end\n    eval_end = min(eval_start + eval_samples, len(task_data))\n    \n    if eval_end - eval_start < eval_samples:\n        # Wrap around if needed\n        eval_subset = task_data[eval_start:] + task_data[:eval_samples - (eval_end - eval_start)]\n    else:\n        eval_subset = task_data[eval_start:eval_end]\n    \n    eval_data[task_name] = eval_subset\n    \n    # Save eval split\n    eval_file = eval_dir / f\"{task_name}_eval.json\"\n    with open(eval_file, \"w\") as f:\n        json.dump(eval_subset, f, indent=2)\n    \n    print(f\"{task_name}: {len(eval_subset)} eval samples saved to {eval_file.name}\")\n\nprint(f\"\\nEval splits saved to: {eval_dir}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Deltas\n",
    "\n",
    "Now compute the delta activations for each adapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Task-specific probes for delta computation\n# Instead of generic probes, we use actual task prompts for better behavioral signal\n\ndef get_task_probes(task_data: List[Dict], num_probes: int = 16) -> List[str]:\n    \"\"\"\n    Get task-specific probes from training data.\n    \n    Uses the actual task prompts (formatted for the model) to compute deltas,\n    giving a much stronger behavioral signal than generic probes.\n    \"\"\"\n    import random\n    \n    # Sample from different parts of the data\n    indices = list(range(len(task_data)))\n    random.seed(42)  # Reproducible\n    random.shuffle(indices)\n    selected = indices[:num_probes]\n    \n    probes = []\n    for idx in selected:\n        item = task_data[idx]\n        system = item.get(\"system\", \"You are a helpful assistant.\")\n        prompt = item[\"prompt\"]\n        \n        # Format as chat prompt (without response - we want model's activation before answering)\n        probe = f\"<|im_start|>system\\n{system}<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n        probes.append(probe)\n    \n    return probes\n\nprint(\"Using task-specific probes for delta computation\")"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from peft import PeftModel\n",
    "\n",
    "def compute_activation(model, tokenizer, probes: List[str], device: str) -> torch.Tensor:\n",
    "    \"\"\"Compute average last-layer, last-token activation over probes.\"\"\"\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for probe in probes:\n",
    "            inputs = tokenizer(probe, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            \n",
    "            # Last layer, last token\n",
    "            last_hidden = outputs.hidden_states[-1]\n",
    "            seq_len = inputs[\"attention_mask\"].sum().item()\n",
    "            last_token_hidden = last_hidden[0, seq_len - 1, :]\n",
    "            activations.append(last_token_hidden)\n",
    "    \n",
    "    return torch.stack(activations).mean(dim=0)\n",
    "\n",
    "\n",
    "def compute_delta(base_model, adapter_path: str, tokenizer, probes: List[str], device: str) -> np.ndarray:\n",
    "    \"\"\"Compute delta = activation(adapted) - activation(base).\"\"\"\n",
    "    \n",
    "    # Base activation\n",
    "    base_act = compute_activation(base_model, tokenizer, probes, device)\n",
    "    \n",
    "    # Load adapter\n",
    "    adapted_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    adapted_model.eval()\n",
    "    \n",
    "    # Adapted activation\n",
    "    adapted_act = compute_activation(adapted_model, tokenizer, probes, device)\n",
    "    \n",
    "    # Delta\n",
    "    delta = (adapted_act - base_act).cpu().float().numpy()\n",
    "    \n",
    "    # Cleanup\n",
    "    del adapted_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model for delta computation...\n",
      "Computing base activation...\n",
      "Base activation shape: torch.Size([896])\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading base model for delta computation...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "base_model.config.output_hidden_states = True\n",
    "base_model.eval()\n",
    "\n",
    "# Compute base activation once\n",
    "print(\"Computing base activation...\")\n",
    "base_activation = compute_activation(base_model, tokenizer, PROBES, device)\n",
    "print(f\"Base activation shape: {base_activation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create deltas directory\ndeltas_dir = output_path / \"deltas\"\ndeltas_dir.mkdir(exist_ok=True)\n\n# Load task data for task-specific probes\ntask_data_cache = {}\nfor task_name, task_info in TASKS.items():\n    data_file = Path(DATA_DIR) / task_info[\"file\"]\n    with open(data_file) as f:\n        task_data_cache[task_name] = json.load(f)\n\n# Compute base activation using a mix of task probes\nprint(\"Computing base activation using task-specific probes...\")\nall_probes = []\nfor task_name, task_data in task_data_cache.items():\n    probes = get_task_probes(task_data, num_probes=8)  # 8 per task = 24 total\n    all_probes.extend(probes)\n\nbase_activation = compute_activation(base_model, tokenizer, all_probes, device)\nprint(f\"Base activation shape: {base_activation.shape}\")\n\n# Save base activation\nnp.save(deltas_dir / \"base_activation.npy\", base_activation.cpu().float().numpy())\n\n# Compute deltas for each adapter using TASK-SPECIFIC probes\ndelta_manifest = {\n    \"base_activation_file\": \"base_activation.npy\",\n    \"num_base_probes\": len(all_probes),\n    \"adapters\": {},\n}\n\nfor adapter_info in tqdm(all_adapters, desc=\"Computing deltas\"):\n    adapter_path = adapter_info[\"path\"]\n    adapter_name = adapter_info[\"name\"]\n    task_name = adapter_info[\"task\"]\n    \n    # Get task-specific probes for this adapter\n    task_data = task_data_cache[task_name]\n    task_probes = get_task_probes(task_data, num_probes=TASKS[task_name][\"delta_probes\"])\n    \n    print(f\"\\nComputing delta for {adapter_name} using {len(task_probes)} {task_name} probes...\")\n    \n    # Compute delta using task-specific probes\n    delta = compute_delta(base_model, adapter_path, tokenizer, task_probes, device)\n    \n    # Save delta\n    delta_file = f\"{adapter_name}_delta.npy\"\n    np.save(deltas_dir / delta_file, delta)\n    \n    # Save the probes used (for reproducibility)\n    probes_file = f\"{adapter_name}_probes.json\"\n    with open(deltas_dir / probes_file, \"w\") as f:\n        json.dump({\"probes\": task_probes, \"task\": task_name}, f, indent=2)\n    \n    delta_manifest[\"adapters\"][adapter_name] = {\n        \"adapter_path\": adapter_path,\n        \"delta_file\": delta_file,\n        \"probes_file\": probes_file,\n        \"task\": task_name,\n        \"num_probes\": len(task_probes),\n        \"delta_norm\": float(np.linalg.norm(delta)),\n    }\n    \n    print(f\"  Delta norm: {np.linalg.norm(delta):.4f}\")\n\n# Save delta manifest\nwith open(deltas_dir / \"delta_manifest.json\", \"w\") as f:\n    json.dump(delta_manifest, f, indent=2)\n\nprint(f\"\\nDeltas saved to: {deltas_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Complete!\n",
      "============================================================\n",
      "\n",
      "Adapters trained: 9\n",
      "Output directory: checkpoints\n",
      "\n",
      "Per-task breakdown:\n",
      "  arc_e: 3 adapters, avg_loss=1.2520\n",
      "  boolq: 3 adapters, avg_loss=1.1413\n",
      "  gsm8k: 3 adapters, avg_loss=0.6428\n",
      "\n",
      "Files created:\n",
      "  - checkpoints/manifest.json\n",
      "  - checkpoints/deltas/delta_manifest.json\n",
      "  - checkpoints/deltas/base_activation.npy\n",
      "  - checkpoints/arc_e/arc_e_000/\n",
      "  - checkpoints/arc_e/arc_e_001/\n",
      "  - checkpoints/arc_e/arc_e_002/\n",
      "  - checkpoints/boolq/boolq_000/\n",
      "  - checkpoints/boolq/boolq_001/\n",
      "  - checkpoints/boolq/boolq_002/\n",
      "  - checkpoints/gsm8k/gsm8k_000/\n",
      "  - checkpoints/gsm8k/gsm8k_001/\n",
      "  - checkpoints/gsm8k/gsm8k_002/\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAdapters trained: {len(all_adapters)}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nPer-task breakdown:\")\n",
    "for task in TASKS:\n",
    "    task_adapters = [a for a in all_adapters if a[\"task\"] == task]\n",
    "    avg_loss = sum(a[\"loss\"] for a in task_adapters) / len(task_adapters)\n",
    "    print(f\"  {task}: {len(task_adapters)} adapters, avg_loss={avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  - {OUTPUT_DIR}/manifest.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/deltas/delta_manifest.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/deltas/base_activation.npy\")\n",
    "for a in all_adapters:\n",
    "    print(f\"  - {a['path']}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify structure\n",
    "!ls -la {OUTPUT_DIR}/\n",
    "print()\n",
    "!ls -la {OUTPUT_DIR}/deltas/ 2>/dev/null || echo \"No deltas dir yet\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llgbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}